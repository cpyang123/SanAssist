{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.46.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (16.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: psutil in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (2.4.1)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: sympy in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ss1516\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "   ---------------------------------------- 0.0/480.6 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 112.6/480.6 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  471.0/480.6 kB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 480.6/480.6 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "   ---------------------------------------- 0.0/320.7 kB ? eta -:--:--\n",
      "   --------------------------------------  317.4/320.7 kB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 320.7/320.7 kB 9.7 MB/s eta 0:00:00\n",
      "Downloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "   ---------------------------------------- 0.0/333.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 333.2/333.2 kB 10.4 MB/s eta 0:00:00\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 143.5/143.5 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, dill, multiprocess, accelerate, datasets, peft\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "Successfully installed accelerate-1.1.1 datasets-3.1.0 dill-0.3.8 multiprocess-0.70.16 peft-0.13.2 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\ss1516\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "import torch\n",
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "# 1. Load the distilgpt2 model and tokenizer\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "# model = GPT2LMHeadModel.from_pretrained('distilgpt2')\n",
    "# # Set the pad_token to eos_token\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.add_special_tokens({'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'})\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "print(\"model loaded\")\n",
    "\n",
    "# 2. Apply LoRA\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print(\"LoRA applied\")\n",
    "model.print_trainable_parameters()\n",
    "print(\"trainable parameters printed\")\n",
    "\n",
    "# 3. Load and format your dataset (same as before)\n",
    "# ... (use the same load_dataset function as earlier)\n",
    "# def load_dataset(file_path):\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         data = json.load(file)\n",
    "    \n",
    "#     # Limit to 1000 examples\n",
    "#     data = data[:100]\n",
    "    \n",
    "#     formatted_data = []\n",
    "#     for item in data:\n",
    "#         instruction = item.get('instruction', '')\n",
    "#         input_text = item.get('input', '')\n",
    "#         output_text = item.get('output', '')\n",
    "        \n",
    "#         # Construct the prompt\n",
    "#         if input_text:\n",
    "#             prompt = f\"{instruction}\\n\\nInput: {input_text}\\n\\nResponse:\"\n",
    "#         else:\n",
    "#             prompt = f\"{instruction}\\n\\nResponse:\"\n",
    "        \n",
    "#         # Combine prompt and output\n",
    "#         full_text = prompt + \" \" + output_text\n",
    "        \n",
    "#         formatted_data.append({'text': full_text})\n",
    "    \n",
    "#     return Dataset.from_dict({'text': [item['text'] for item in formatted_data]})\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "   \n",
    "    data = data[:1000] #2k \n",
    "    \n",
    "    formatted_data = []\n",
    "    for item in data:\n",
    "        instruction = \"You are an experienced medical doctor specializing in mental health. Provide a detailed and compassionate response to the patient's description.\" #item.get('instruction', '')\n",
    "        input_text = item.get('input', '')\n",
    "        output_text = item.get('output', '')\n",
    "        \n",
    "        # Construct the prompt\n",
    "        if input_text:\n",
    "            prompt = f\"{instruction}\\n\\nPatient's Description: {input_text}\\n\\nDoctor's Response\"\n",
    "        else:\n",
    "            prompt = f\"{instruction}\\n\\nDoctor's Response\"\n",
    "        \n",
    "        formatted_data.append({\n",
    "            'text': prompt,\n",
    "            'label': output_text\n",
    "        })\n",
    "    \n",
    "    return Dataset.from_dict({\n",
    "        'text': [item['text'] for item in formatted_data],\n",
    "        'label': [item['label'] for item in formatted_data]\n",
    "    })\n",
    "\n",
    "\n",
    "dataset = load_dataset('chatdoctor5k.json')  #'chatdoctor5k.json')\n",
    "\n",
    "# 4. Tokenize the dataset\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples['text'], truncation=True, padding=\"longest\", max_length=128 )\n",
    "\n",
    "# tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        padding='longest'\n",
    "    )\n",
    "    outputs = tokenizer(\n",
    "        examples['label'],\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        padding='longest'\n",
    "    )\n",
    "    \n",
    "    # Concatenate the inputs and outputs\n",
    "    input_ids = []\n",
    "    labels = []\n",
    "    attention_masks = []\n",
    "    for i in range(len(inputs['input_ids'])):\n",
    "        input_id = inputs['input_ids'][i] + outputs['input_ids'][i]\n",
    "        attention_mask = inputs['attention_mask'][i] + outputs['attention_mask'][i]\n",
    "        label = [-100] * len(inputs['input_ids'][i]) + outputs['input_ids'][i]\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_masks,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "# tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset.column_names  # Remove original columns\n",
    ")\n",
    "\n",
    "# 5. Prepare data collator\n",
    "from transformers import default_data_collator\n",
    "\n",
    "data_collator = default_data_collator\n",
    "\n",
    "# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# 6. Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./lora_results',\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=4, #4 or 8\n",
    "    num_train_epochs=3, #3 or more\n",
    "    logging_steps=10,\n",
    "    save_steps=50,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    gradient_accumulation_steps=1,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=200,\n",
    ")\n",
    "\n",
    "# 7. Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "# 8. Train the model\n",
    "trainer.train()\n",
    "\n",
    "# 9. Save the LoRA adapter\n",
    "model.save_pretrained('./trained_lora_2k')\n",
    "tokenizer.save_pretrained('./trained_lora_2k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an experienced medical doctor specializing in mental health. Provide a detailed and compassionate response to the patient's description.\n",
      "\n",
      "Patient's Description: I have been experiencing sudden and frequent panic attacks.\n",
      "\n",
      "Doctor's Response: It is normal for you, especially if your symptoms aren't completely consistent with what we've described here. However there may be some other conditions that might indicate something more serious than sleep apnea or dizziness. We'll need blood tests to confirm those factors (including any abnormal oxygenation levels), neurological imaging procedures to check your breathing, psychological evaluation of possible medications used to treat this condition such as medication changes, etc., so that we can diagnose it correctly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('./trained_lora')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('./trained_lora')\n",
    "\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval()\n",
    "\n",
    "# Prepare a prompt\n",
    "instruction = \"You are an experienced medical doctor specializing in mental health. Provide a detailed and compassionate response to the patient's description.\"\n",
    "input_text = \"I have been experiencing sudden and frequent panic attacks.\"\n",
    "prompt = f\"{instruction}\\n\\nPatient's Description: {input_text}\\n\\nDoctor's Response:\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # outputs = model.generate(\n",
    "    #     **inputs,\n",
    "    #     max_new_tokens=100,\n",
    "    #     do_sample=True,\n",
    "    #     top_p=0.9,\n",
    "    #     temperature=0.75,\n",
    "    # )\n",
    "    outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    "    no_repeat_ngram_size=3,\n",
    ")\n",
    "\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
